{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31acf4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import os,cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import os, os.path\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers, optimizers,initializers\n",
    "from tensorflow.keras.layers import BatchNormalization,MaxPool2D\n",
    "from tensorflow.keras.models import Sequential,Model,load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten,Input,Conv2DTranspose,concatenate,GlobalAveragePooling2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "250c117d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00a89194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile('train.zip','a') as z:\n",
    "    z.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb9b329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id  label\n",
       "0        0      0\n",
       "1        1      0\n",
       "2        2      0\n",
       "3        3      0\n",
       "4        4      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64845d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1709, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20ebc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFileName(filename):\n",
    "    field_id = filename.rsplit('\\\\',1)[1]\n",
    "    field_id = field_id.rsplit('.',1)[0]\n",
    "    return field_id\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24a5ede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_label(filename):\n",
    "    field_id = filename.rsplit('\\\\',1)[1]\n",
    "    field_id = field_id.rsplit('.',1)[0]\n",
    "    x =  int(train_data[train_data['file_id'] == int(field_id)]['label'])\n",
    "    return x\n",
    "    \n",
    "    #return int(train_data[train_data['file_id'] == int(field_id)]['label'])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7089fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Venkat K Pillai\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(1, 950, '949')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train_data['label'])\n",
    "plt.xlabel('Fake vs Real')\n",
    "plt.text(x=0,y=770,s=train_data.value_counts('label')[0])\n",
    "plt.text(x=1,y=950,s=train_data.value_counts('label')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0833183",
   "metadata": {},
   "source": [
    " Merge fake and real images folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed89ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c468eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAgumentedData(label,img):\n",
    "    label_list = []\n",
    "    file_list  = []\n",
    "    datagen = ImageDataGenerator(rotation_range = 40,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True,brightness_range = (0.5, 1.5))\n",
    "    img = img\n",
    "    x = img_to_array(img)\n",
    "    x = x.reshape((1, ) + x.shape) \n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size = 1,save_to_dir ='preview',save_prefix ='image', save_format ='jpg'):\n",
    "        i += 1   \n",
    "        if i > 3:\n",
    "            break\n",
    "    allfiles = os.listdir('preview')\n",
    " \n",
    "    for f in allfiles:\n",
    "        file_list.append(f)\n",
    "        label_list.append(label)\n",
    "        shutil.move('./preview/' + f, './train/' + f)\n",
    "    return file_list,label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4544609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images to system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f3e7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(mode):\n",
    "    count = 0\n",
    "    if(mode == \"Train\"):\n",
    "        images_folder = \"train\"\n",
    "        filenames = [os.path.join(images_folder,file) for file in os.listdir(images_folder) if file.endswith(\".jpg\")]\n",
    "        images = []\n",
    "        labels = []\n",
    "        global agumented_images\n",
    "        agumented_images = []\n",
    "        global agumented_labels\n",
    "        agumented_labels = []\n",
    "        for f in filenames:\n",
    "            img = Image.open(f)\n",
    "            label = target_label(f)\n",
    "            #f1,l1 = addAgumentedData(label,img)\n",
    "            #agumented_images.extend(f1)\n",
    "            #agumented_labels.extend(l1)\n",
    "                #train_data = train_data.append({'file_id':f1, 'label':l1}, ignore_index=True)\n",
    "            # Resize images to 256x256.\n",
    "            img = img.resize((256, 256), Image.ANTIALIAS)\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            # Normalize the images.\n",
    "            img = img / 255.\n",
    "            images.append(img)\n",
    "            #label = arget_label(f)\n",
    "            #addAgumentedData(f,label)\n",
    "            #label = np.expand_dims(label, axis=0)\n",
    "            #label = label / 255.\n",
    "            labels.append(label)\n",
    "        images = np.array(images)\n",
    "        labels = np.array(labels)\n",
    "        return images, labels\n",
    "    \n",
    "    if mode == \"Test\":\n",
    "        images_folder = \"test\"\n",
    "        labels_folder = \"test_label\"\n",
    "        if not os.path.isdir(\"test_label\"):\n",
    "            os.makedirs(\"test_label\")\n",
    "        filenames = [os.path.join(images_folder,file) for file in os.listdir(images_folder) if file.endswith(\".jpg\")]\n",
    "        images = []\n",
    "        label_name = []\n",
    "        height = []\n",
    "        width = []\n",
    "        for f in filenames:\n",
    "            img = Image.open(f)\n",
    "            width.append(img.size[0])\n",
    "            height.append(img.size[1])\n",
    "            img = img.resize((128, 128), Image.ANTIALIAS)\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "            img = img / 255.\n",
    "            images.append(img)\n",
    "            #id = re.search(\"Unet_usecase/test_raw/(.+).jpg\", f).group(1)\n",
    "            #label_file = labels_folder+\"/\"+id+\".jpg\"\n",
    "            label_name.append(getFileName(f))\n",
    "        images = np.array(images)\n",
    "        label_name = np.array(label_name)\n",
    "        height = np.array(height)\n",
    "        width = np.array(width)\n",
    "        return images, label_name, height, width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44059776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(input_shape=(128,128,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
    "    model.add(Flatten(name='flatten'))\n",
    "    model.add(Dense(256, activation='relu', name='fc1'))\n",
    "    model.add(Dense(128, activation='relu', name='fc2'))\n",
    "    model.add(Dense(2, activation='sigmoid', name='output'))\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a43b5504",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#images, labels = load_data(mode=\"Train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dff9254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1709, 1709)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images),len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f53a5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 128, 128, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 128, 128, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 64, 64, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 64, 64, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 64, 64, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " vgg16 (MaxPooling2D)        (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 256)               2097408   \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 128)               32896     \n",
      "                                                                 \n",
      " output (Dense)              (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,845,250\n",
      "Trainable params: 16,845,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = unet_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6f16ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5c01880",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_h = 128\n",
    "img_size_w = 128\n",
    "\n",
    "X = np.ndarray(shape=(len(images),img_size_h,img_size_w,3), dtype=np.int32)\n",
    "X = X/255.\n",
    "X = X.reshape(-1, 128, 128, 3)\n",
    "y = np.array(labels)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=10) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c0c01ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1367, 128, 128, 3)\n",
      "(1367,)\n",
      "(342, 128, 128, 3)\n",
      "(342,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1dea791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10),\n",
    "    ModelCheckpoint(filepath='model_checkpoint.hdf5', monitor='val_loss', save_best_only=True, mode ='max'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d26022c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 100\n",
    "#early_stopping = EarlyStopping(monitor='accuracy',min_delta=0,patience=2,verbose=0, mode='auto')\n",
    "#history = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6de5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size = 100, epochs =5 ,validation_data = (X_test, y_test),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6d7b061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 10s 902ms/step - loss: 0.6886 - accuracy: 0.5673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6885614395141602, 0.567251443862915]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.evaluate(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1488eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 183ms/step - loss: 0.6882 - accuracy: 0.5673\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6882418990135193, 0.567251443862915]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871f217a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5de96080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file -p already exists.\n",
      "Error occurred while processing: -p.\n",
      "A subdirectory or file saved_model already exists.\n",
      "Error occurred while processing: saved_model.\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('saved_model/FakeOrReal_trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0f169e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_model = tf.keras.models.load_model('saved_model/FakeOrReal_trained_model.h5')\n",
    "#trained_model.set_weights(trained_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8196961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"saved_model/FakeOrReal_trained_model.h5\")\n",
    "loaded_model.set_weights(loaded_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "aabb1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, label_names, height, width = load_data(mode=\"Test\")\n",
    "label_predict = []\n",
    "label_predict = np.argmax(loaded_model.predict(images), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cba1549f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b5107bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>95</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>332 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file_id  label\n",
       "0         0      1\n",
       "1         1      1\n",
       "2        10      1\n",
       "3       100      1\n",
       "4       101      1\n",
       "..      ...    ...\n",
       "327      95      1\n",
       "328      96      0\n",
       "329      97      0\n",
       "330      98      1\n",
       "331      99      0\n",
       "\n",
       "[332 rows x 2 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = pd.DataFrame({'file_id':label_names,'label':label_predict})\n",
    "df_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "120239f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    166\n",
       "1    166\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a57edecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_output.to_csv('venkat_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7774dc5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f730de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
